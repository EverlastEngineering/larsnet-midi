# Debugging Scripts Architecture

## File Organization

```
debugging_scripts/
â”‚
â”œâ”€â”€ ğŸ“Š DATA
â”‚   â”œâ”€â”€ data.csv                          # Training data (spectral features)
â”‚   â”œâ”€â”€ optimal_rules.csv                 # Grid search results
â”‚   â”œâ”€â”€ bayesian_optimal_rules.csv        # Bayesian optimization results
â”‚   â””â”€â”€ random_search_results.csv         # Random search results
â”‚
â”œâ”€â”€ ğŸ”§ CORE TOOLS
â”‚   â”œâ”€â”€ classifier.py                     # ML pattern analysis
â”‚   â”œâ”€â”€ threshold_optimizer.py            # Grid search optimizer
â”‚   â”œâ”€â”€ bayesian_optimizer.py             # Bayesian optimization
â”‚   â””â”€â”€ random_search_optimizer.py        # Random search + analysis
â”‚
â”œâ”€â”€ ğŸ¯ UTILITIES
â”‚   â”œâ”€â”€ compare_optimizers.py             # Run & compare all methods
â”‚   â””â”€â”€ example_optimization_workflow.py  # Educational demo
â”‚
â””â”€â”€ ğŸ“š DOCUMENTATION
    â”œâ”€â”€ README.md                         # Comprehensive guide
    â”œâ”€â”€ QUICK_START.md                    # User quick reference
    â”œâ”€â”€ OPTIMIZATION_METHODS.md           # Technical deep dive
    â”œâ”€â”€ WHATS_NEW.md                      # New features overview
    â”œâ”€â”€ ARCHITECTURE.md                   # This file
    â””â”€â”€ REQUIREMENTS.txt                  # Python dependencies
```

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AUDIO PROCESSING                          â”‚
â”‚                                                                  â”‚
â”‚  Audio File â†’ stems_to_midi.py â†’ Spectral Analysis Output       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“ (copy table)
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   data.csv      â”‚ â† Manual labeling
                   â”‚  (160 samples)  â”‚   (mark open hi-hats)
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚                  â”‚
         â†“                  â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  classifier.py â”‚  â”‚ Grid Search    â”‚  â”‚ Random Search  â”‚
â”‚                â”‚  â”‚                â”‚  â”‚                â”‚
â”‚ Feature        â”‚  â”‚ 1,800 combos   â”‚  â”‚ 10,000 samples â”‚
â”‚ Importance     â”‚  â”‚ ~12 seconds    â”‚  â”‚ ~3 seconds     â”‚
â”‚                â”‚  â”‚                â”‚  â”‚                â”‚
â”‚ Decision Rules â”‚  â”‚ Exhaustive     â”‚  â”‚ Statistical    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                    â”‚
                            â†“                    â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚optimal_rules.csvâ”‚  â”‚random_search.csvâ”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bayesian Opt    â”‚
â”‚                 â”‚
â”‚ 100 calls       â”‚
â”‚ ~9 seconds      â”‚
â”‚                 â”‚
â”‚ Learns & Refinesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚bayesian_optimal_rules.csvâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            COMPARISON & SELECTION             â”‚
â”‚                                               â”‚
â”‚  compare_optimizers.py                        â”‚
â”‚  â”œâ”€ Performance metrics                       â”‚
â”‚  â”œâ”€ Quality comparison                        â”‚
â”‚  â””â”€ Recommendations                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  BEST RULE    â”‚
            â”‚               â”‚
            â”‚ GeoMean > 300 â”‚
            â”‚ Sustain > 80  â”‚
            â”‚ BodyE > 50    â”‚
            â”‚ Margin: 49.3% â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   midiconfig.yaml    â”‚ â†’ stems_to_midi/detection.py
         â”‚  (configuration)     â”‚   (implementation)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Algorithm Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GRID SEARCH                                 â”‚
â”‚                                                                     â”‚
â”‚  Parameter Space:        Evaluation Strategy:                      â”‚
â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”      â€¢ Test every grid point                   â”‚
â”‚  â”‚ â— â”‚ â— â”‚ â— â”‚ â— â”‚      â€¢ Deterministic, exhaustive               â”‚
â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤      â€¢ Guarantees finding best in grid         â”‚
â”‚  â”‚ â— â”‚ â— â”‚ â— â”‚ â— â”‚                                                â”‚
â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤      Complexity: O(n^d)                        â”‚
â”‚  â”‚ â— â”‚ â— â”‚ â— â”‚ â— â”‚      Time: ~12 seconds                         â”‚
â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤      Results: 141 perfect rules                â”‚
â”‚  â”‚ â— â”‚ â— â”‚ â— â”‚ â— â”‚                                                â”‚
â”‚  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RANDOM SEARCH                                 â”‚
â”‚                                                                     â”‚
â”‚  Parameter Space:        Evaluation Strategy:                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â€¢ Sample uniformly at random               â”‚
â”‚  â”‚   â— â—           â”‚    â€¢ Independent samples                      â”‚
â”‚  â”‚ â—   â—  â—  â—     â”‚    â€¢ Unbiased exploration                     â”‚
â”‚  â”‚    â—    â—   â—   â”‚                                               â”‚
â”‚  â”‚ â—    â—      â—   â”‚    Complexity: O(n)                           â”‚
â”‚  â”‚   â—   â—  â—      â”‚    Time: ~3 seconds                           â”‚
â”‚  â”‚ â—      â—    â—   â”‚    Results: 847 perfect rules                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BAYESIAN OPTIMIZATION                            â”‚
â”‚                                                                     â”‚
â”‚  Parameter Space:        Evaluation Strategy:                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â€¢ Build Gaussian Process model             â”‚
â”‚  â”‚ 1 2             â”‚    â€¢ Use acquisition function (EI)            â”‚
â”‚  â”‚   3 4 5         â”‚    â€¢ Balance exploitation vs exploration      â”‚
â”‚  â”‚      6 7 8 9    â”‚    â€¢ Learn from previous evaluations          â”‚
â”‚  â”‚         â—â—â—     â”‚                                               â”‚
â”‚  â”‚         â—â—â—     â”‚    Complexity: O(nÂ³) per iteration            â”‚
â”‚  â”‚         â—â—â—     â”‚    Time: ~9 seconds                           â”‚
â”‚  â”‚   (converges    â”‚    Results: 12 perfect rules (targeted)       â”‚
â”‚  â”‚    to optimum)  â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚  Numbers show evaluation order â†’ concentrates on best region       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Method Selection Decision Tree

```
                        Start Here
                            â”‚
                            â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ What's your primary goal?    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
        â†“           â†“           â†“
    Explore     Refine     Verify
    (First)    (Improve)   (Final)
        â”‚           â”‚           â”‚
        â†“           â†“           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Random   â”‚ â”‚ Bayesian â”‚ â”‚   Grid   â”‚
  â”‚ Search   â”‚ â”‚   Opt    â”‚ â”‚  Search  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ compare_optimizers.py â”‚
          â”‚                       â”‚
          â”‚ Runs all three and    â”‚
          â”‚ provides comparison   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Information Flow Between Tools

```
classifier.py
    â”‚
    â”œâ”€â†’ Feature Importance Rankings
    â”‚   (Which features matter?)
    â”‚
    â””â”€â†’ Decision Tree Rules
        (Human-readable patterns)
            â†“
        Informs search ranges for:
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
    â†“               â†“
threshold_optimizer  random_search_optimizer
    â”‚                       â”‚
    â”‚                       â”œâ”€â†’ Distribution Analysis
    â”‚                       â”‚   (Parameter statistics)
    â”‚                       â”‚
    â”‚                       â”œâ”€â†’ Robust Regions
    â”‚                       â”‚   (Stable parameter areas)
    â”‚                       â”‚
    â”‚                       â””â”€â†’ Feature Correlations
    â”‚                           (How thresholds interact)
    â”‚                               â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        Candidate Solutions
                â†“
        bayesian_optimizer.py
                â”‚
                â”œâ”€â†’ Convergence Analysis
                â”‚   (Learning progress)
                â”‚
                â”œâ”€â†’ Objective Landscape
                â”‚   (Function topology)
                â”‚
                â””â”€â†’ Uncertainty Estimates
                    (Confidence intervals)
                        â†“
                Final Recommendations
```

## Execution Patterns

### Pattern 1: Quick & Dirty
```bash
python threshold_optimizer.py
# Use grid search results directly
# Time: 12 seconds
```

### Pattern 2: Exploratory
```bash
python random_search_optimizer.py --n-samples 50000 --visualize
# Understand parameter space thoroughly
# Time: ~5 seconds + visualization
```

### Pattern 3: Efficient
```bash
pip install scikit-optimize
python bayesian_optimizer.py --n-calls 200
# Sample-efficient optimization
# Time: ~15 seconds
```

### Pattern 4: Comprehensive (Recommended)
```bash
# Phase 1: Explore
python random_search_optimizer.py --n-samples 50000

# Phase 2: Refine
python bayesian_optimizer.py --n-calls 100

# Phase 3: Verify
python threshold_optimizer.py

# Compare all results
python compare_optimizers.py
# Total time: ~35 seconds
```

### Pattern 5: One-Shot
```bash
python compare_optimizers.py
# Runs all three automatically
# Time: ~30 seconds
```

### Pattern 6: Educational
```bash
python example_optimization_workflow.py
# See all three phases in action
# Demonstrates recommended workflow
# Time: ~20 seconds
```

## Output Files

### CSV Results Structure

**optimal_rules.csv** (Grid Search):
```csv
rule,n_features,recall,precision,tp,fp,fn,margin_score,GeoMean,SustainMs,BodyE
GeoMean > 300 AND ...,3,1.0,1.0,6,0,0,49.3,300,80.0,50.0
```

**bayesian_optimal_rules.csv** (Bayesian Optimization):
```csv
rule,n_features,score,margin,recall,precision,GeoMean,SustainMs,BodyE
GeoMean > 300 AND ...,3,149.2,49.2,1.0,1.0,300.0,80.0,50.0
```

**random_search_results.csv** (Random Search):
```csv
rule,margin,GeoMean,SustainMs,BodyE
GeoMean > 305.2 AND ...,48.7,305.2,83.4,52.1
```

All three formats can be:
1. Sorted by margin to find best rules
2. Filtered by n_features for different complexity levels
3. Analyzed for parameter distributions
4. Exported to midiconfig.yaml

## Integration Points

### Current State
```
debugging_scripts/ â†’ Manual review â†’ midiconfig.yaml â†’ stems_to_midi/detection.py
```

### Future State (Planned)
```
debugging_scripts/
    â”‚
    â”œâ”€â†’ optimize_config.py (wizard)
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Automatic data generation
    â”‚       â”œâ”€â†’ Interactive labeling
    â”‚       â”œâ”€â†’ Run optimal optimizer
    â”‚       â””â”€â†’ Update midiconfig.yaml
    â”‚
    â””â”€â†’ midiconfig.yaml (enhanced schema)
            â”‚
            â””â”€â†’ stems_to_midi/detection.py (multi-feature rules)
```

See `ml-driven-threshold-config.plan.md` for full integration roadmap.

## Dependencies Graph

```
Core Dependencies (in conda env):
    pandas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    numpy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ All scripts
    scikit-learn â”€â”€â”€â”¤
    matplotlib â”€â”€â”€â”€â”€â”˜

Optional Dependencies:
    scikit-optimize â”€â†’ bayesian_optimizer.py
    seaborn â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ random_search_optimizer.py (enhanced viz)
```

## Performance Characteristics

```
Script                      Time    Memory   Disk Output
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
classifier.py               <1s     ~50MB    stdout
threshold_optimizer.py      12s     ~100MB   optimal_rules.csv (30 rows)
random_search_optimizer.py  3-5s    ~200MB   random_search_results.csv (30 rows)
                                              + PNG visualizations (3 files)
bayesian_optimizer.py       8-10s   ~150MB   bayesian_optimal_rules.csv (8 rows)
                                              + PNG plots (3-6 files)
compare_optimizers.py       25-35s  ~300MB   All CSV + comparison report
example_workflow.py         15-20s  ~100MB   stdout (educational demo)
```

## Extension Points

Future enhancements can be added:

```
debugging_scripts/
    â”‚
    â”œâ”€â†’ NEW: multi_objective_optimizer.py
    â”‚        (Optimize margin + simplicity simultaneously)
    â”‚
    â”œâ”€â†’ NEW: active_learning.py
    â”‚        (Suggest which examples to label next)
    â”‚
    â”œâ”€â†’ NEW: transfer_learning.py
    â”‚        (Use rules from other projects as prior)
    â”‚
    â””â”€â†’ NEW: ensemble_classifier.py
            (Combine multiple rules with voting)
```

## Testing Strategy

To validate optimizers:
1. Run on known dataset (`data.csv`)
2. Verify all find similar optimal margin (~49%)
3. Check consistency across runs (with fixed seed)
4. Validate against manual threshold testing
5. Test on new projects (generalization)

---

**Last Updated**: 2025-10-31
